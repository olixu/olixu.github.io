<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="keywords" content="Hexo Theme Redefine"><meta name="author" content="Oliver xu"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="canonical" href="https://blog.oliverxu.cn/2021/01/31/科研论文常用句式语法汇总整理/"><meta name="robots" content="index,follow"><meta name="googlebot" content="index,follow"><meta name="revisit-after" content="1 days"><meta name="description" content="科研论文写作和平常的写作不太一样，从我自己写下来的感觉，发现自己写的英文句式很死板，读上去没有那些native的作者的语言的感觉，因此需要进行专业训练。训练方式就是模仿那些作者的文字。 这篇博客将长期更新，分为5个部分，包括abstract, Introduction, method, simulation, conclusion，争取做到每天更新，每天看一篇论文，在学习其内容的同时，整理其值得学"><meta property="og:type" content="article"><meta property="og:title" content="科研论文常用句式语法汇总整理"><meta property="og:url" content="https://blog.oliverxu.cn/2021/01/31/%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87%E5%B8%B8%E7%94%A8%E5%8F%A5%E5%BC%8F%E8%AF%AD%E6%B3%95%E6%B1%87%E6%80%BB%E6%95%B4%E7%90%86/index.html"><meta property="og:site_name" content="Oliver xu&#39;s Blog"><meta property="og:description" content="科研论文写作和平常的写作不太一样，从我自己写下来的感觉，发现自己写的英文句式很死板，读上去没有那些native的作者的语言的感觉，因此需要进行专业训练。训练方式就是模仿那些作者的文字。 这篇博客将长期更新，分为5个部分，包括abstract, Introduction, method, simulation, conclusion，争取做到每天更新，每天看一篇论文，在学习其内容的同时，整理其值得学"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2021-01-31T19:09:00.000Z"><meta property="article:modified_time" content="2026-02-28T21:09:01.195Z"><meta property="article:author" content="Oliver xu"><meta property="article:tag" content="Paper"><meta name="twitter:card" content="summary"><link rel="icon" type="image/png" href="/images/avatar.jpeg" sizes="192x192"><link rel="apple-touch-icon" sizes="180x180" href="/images/avatar.jpeg"><meta name="theme-color" content="#A31F34"><link rel="shortcut icon" href="/images/avatar.jpeg"><title>科研论文常用句式语法汇总整理 | Oliver xu&#39;s Blog</title><link rel="stylesheet" href="/fonts/Chillax/chillax.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/assets/build/styles.css"><link rel="stylesheet" href="/fonts/GeistMono/geist-mono.css"><link rel="stylesheet" href="/fonts/Geist/geist.css"><script id="hexo-configurations">window.config={hostname:"blog.oliverxu.cn",root:"/",language:"zh-CN",path:"search.xml"},window.theme={articles:{style:{font_size:"16px",line_height:1.5,image_border_radius:"14px",image_alignment:"center",image_caption:!1,link_icon:!0,title_alignment:"left",headings_top_spacing:{h1:"3.2rem",h2:"2.4rem",h3:"1.9rem",h4:"1.6rem",h5:"1.4rem",h6:"1.3rem"}},word_count:{enable:!0,count:!0,min2read:!0},author_label:{enable:!1,auto:!1,list:[]},code_block:{copy:!0,style:"mac",highlight_theme:{light:"github",dark:"vs2015"},font:{enable:!1,family:null,url:null}},toc:{enable:!0,max_depth:3,number:!1,expand:!0,init_open:!0},copyright:{enable:!0,default:"cc_by_nc_sa"},lazyload:!0,recommendation:{enable:!1,title:"推荐阅读",limit:3,mobile_limit:2,placeholder:"/images/wallhaven-wqery6-light.webp",skip_dirs:[]}},colors:{primary:"#A31F34",secondary:null,default_mode:"light"},global:{fonts:{chinese:{enable:!1,family:null,url:null},english:{enable:!1,family:null,url:null},title:{enable:!1,family:null,url:null}},content_max_width:"1000px",sidebar_width:"210px",hover:{shadow:!0,scale:!1},scroll_progress:{bar:!0,percentage:!0},website_counter:{url:"https://cn.vercount.one/js",enable:!0,site_pv:!0,site_uv:!0,post_pv:!0},single_page:!0,preloader:{enable:!1,custom_message:null},open_graph:!0,google_analytics:{enable:!1,id:null}},home_banner:{enable:!0,style:"fixed",image:{light:"/images/xinjiang.webp",dark:"/images/xinjiang.webp"},title:"美好的事情即将发生",subtitle:{text:[],hitokoto:{enable:!1,show_author:!1,api:"https://v1.hitokoto.cn"},typing_speed:100,backing_speed:80,starting_delay:500,backing_delay:1500,loop:!0,smart_backspace:!0},text_color:{light:"#fff",dark:"#d1d1b6"},text_style:{title_size:"2.8rem",subtitle_size:"1.5rem",line_height:1.2},custom_font:{enable:!1,family:null,url:null},social_links:{enable:!0,style:"default",links:{github:"https://github.com/olixu",instagram:null,zhihu:null,twitter:null,email:null},qrs:{weixin:null}}},plugins:{feed:{enable:!1},aplayer:{enable:!1,type:"fixed",audios:[{name:null,artist:null,url:null,cover:null,lrc:null}]},mermaid:{enable:!1,version:"9.3.0"}},version:"2.7.3",navbar:{auto_hide:!1,color:{left:"#f78736",right:"#367df7",transparency:35},width:{home:"1200px",pages:"1000px"},links:{Home:{path:"/",icon:"fa-regular fa-house"},about:{path:"/about",icon:"fa fa-user"},tags:{path:"/tags",icon:"fa fa-tags"},archives:{path:"/archives",icon:"fa fa-archive"},album:{path:"/album",icon:"fa fa-images"}},search:{enable:!0,preload:!0}},page_templates:{friends_column:2,tags_style:"blur"},home:{sidebar:{enable:!0,position:"left",first_item:"menu",announcement:null,show_on_mobile:!0,links:null},article_date_format:"auto",excerpt_length:200,categories:{enable:!0,limit:3},tags:{enable:!0,limit:3}},footerStart:"2019/1/1 00:00:00"},window.lang_ago={second:"%s 秒前",minute:"%s 分钟前",hour:"%s 小时前",day:"%s 天前",week:"%s 周前",month:"%s 个月前",year:"%s 年前"},window.data={masonry:!1}</script><link rel="stylesheet" href="/fontawesome/fontawesome.min.css"><link rel="stylesheet" href="/fontawesome/brands.min.css"><link rel="stylesheet" href="/fontawesome/solid.min.css"><link rel="stylesheet" href="/fontawesome/regular.min.css"><meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div class="progress-bar-container"><span class="scroll-progress-bar"></span> <span class="pjax-progress-bar"></span></div><main class="page-container" id="swup"><div class="main-content-container flex flex-col justify-between min-h-dvh"><div class="main-content-header"><header class="navbar-container px-6 md:px-12"><div class="navbar-content transition-navbar"><div class="left"><a class="logo-title" href="/">Oliver xu&#39;s Blog</a></div><div class="right"><div class="desktop"><ul class="navbar-list"><li class="navbar-item"><a href="/"><i class="fa-regular fa-house fa-fw"></i> 首页</a></li><li class="navbar-item"><a href="/about"><i class="fa fa-user fa-fw"></i> 关于</a></li><li class="navbar-item"><a href="/tags"><i class="fa fa-tags fa-fw"></i> 标签</a></li><li class="navbar-item"><a href="/archives"><i class="fa fa-archive fa-fw"></i> 归档</a></li><li class="navbar-item"><a href="/album"><i class="fa fa-images fa-fw"></i> ALBUM</a></li><li class="navbar-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i></li></ul></div><div class="mobile"><div class="icon-item search search-popup-trigger"><i class="fa-solid fa-magnifying-glass"></i></div><div class="icon-item navbar-bar"><div class="navbar-bar-middle"></div></div></div></div></div><div class="navbar-drawer h-dvh w-full absolute top-0 left-0 bg-background-color flex flex-col justify-between"><ul class="drawer-navbar-list flex flex-col px-4 justify-center items-start"><li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full"><a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full" href="/"><span>首页 </span><i class="fa-regular fa-house fa-sm fa-fw"></i></a></li><li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full"><a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full" href="/about"><span>关于 </span><i class="fa fa-user fa-sm fa-fw"></i></a></li><li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full"><a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full" href="/tags"><span>标签 </span><i class="fa fa-tags fa-sm fa-fw"></i></a></li><li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full"><a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full" href="/archives"><span>归档 </span><i class="fa fa-archive fa-sm fa-fw"></i></a></li><li class="drawer-navbar-item text-base my-1.5 flex flex-col w-full"><a class="py-1.5 px-2 flex flex-row items-center justify-between gap-1 hover:!text-primary active:!text-primary text-2xl font-semibold group border-b border-border-color hover:border-primary w-full" href="/album"><span>ALBUM </span><i class="fa fa-images fa-sm fa-fw"></i></a></li></ul><div class="statistics flex justify-around my-2.5"><a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/tags"><div class="number text-2xl sm:text-xl text-second-text-color font-semibold">45</div><div class="label text-third-text-color text-sm">标签</div></a><a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/categories"><div class="number text-2xl sm:text-xl text-second-text-color font-semibold">42</div><div class="label text-third-text-color text-sm">分类</div></a><a class="item tag-count-item flex flex-col justify-center items-center w-20" href="/archives"><div class="number text-2xl sm:text-xl text-second-text-color font-semibold">94</div><div class="label text-third-text-color text-sm">文章</div></a></div></div><div class="window-mask"></div></header></div><div class="main-content-body"><div class="main-content"><div class="post-page-container flex relative justify-between box-border w-full h-full"><div class="article-content-container"><div class="article-title relative w-full"><div class="w-full flex items-center pt-6 justify-start"><h1 class="article-title-regular text-second-text-color tracking-tight text-4xl md:text-6xl font-semibold px-2 sm:px-6 md:px-8 py-3">科研论文常用句式语法汇总整理</h1></div></div><div class="article-header flex flex-row gap-2 items-center px-2 sm:px-6 md:px-8"><div class="avatar w-[46px] h-[46px] flex-shrink-0 rounded-medium border border-border-color p-[1px]"><img src="/images/avatar.jpeg"></div><div class="info flex flex-col justify-between"><div class="author flex items-center"><span class="name text-default-text-color text-lg font-semibold">Oliver xu</span></div><div class="meta-info"><div class="article-meta-info"><span class="article-date article-meta-item"><i class="fa-regular fa-pen-fancy"></i>&nbsp; <span class="desktop">2021-01-31 19:09</span> <span class="mobile">2021-01-31 19:09</span> <span class="hover-info">创建</span> </span><span class="article-date article-meta-item"><i class="fa-regular fa-wrench"></i>&nbsp; <span class="desktop">2026-02-28 21:09:01</span> <span class="mobile">2026-02-28 21:09:01</span> <span class="hover-info">更新</span> </span><span class="article-categories article-meta-item"><i class="fa-regular fa-folders"></i>&nbsp;<ul><li><a href="/categories/Paper/">Paper</a>&nbsp;</li></ul></span><span class="article-tags article-meta-item"><i class="fa-regular fa-tags"></i>&nbsp;<ul><li><a href="/tags/Paper/">Paper</a>&nbsp;</li></ul></span><span class="article-wordcount article-meta-item"><i class="fa-regular fa-typewriter"></i>&nbsp;<span>5k 字</span> </span><span class="article-min2read article-meta-item"><i class="fa-regular fa-clock"></i>&nbsp;<span>22 分钟</span> </span><span class="article-pv article-meta-item"><i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span></span></div></div></div></div><div class="article-content markdown-body px-2 sm:px-6 md:px-8 pb-8"><p>科研论文写作和平常的写作不太一样，从我自己写下来的感觉，发现自己写的英文句式很死板，读上去没有那些native的作者的语言的感觉，因此需要进行专业训练。训练方式就是模仿那些作者的文字。</p><p>这篇博客将长期更新，分为5个部分，包括abstract, Introduction, method, simulation, conclusion，争取做到每天更新，每天看一篇论文，在学习其内容的同时，整理其值得学习借鉴的语法句式，分类整理。</p><p>对于每一篇文章，每一个section找5句有特色的句子，将其中文意思和英文表单都整理一下，因为从实际写作的角度来看，很多情况下我们无法写出合适的英文表达，有一部分原因是因为我们使用中文都无法准确将我们想要表达的内容表达出来，所以英译汉也是一个十分重要的部分。</p><p>通过不断整理，相当于整理了一个可供中文查询的数据库，例如，我想搜"关系"，直接可以搜到整理到的相关的语句表达。</p><p>在阅读文献的时候，将好的语句表达用不同颜色标注一下。</p><span id="more"></span><h2 id="abstract">Abstract</h2><p>We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments.</p><p>我们介绍了Adam，一种基于自适应低阶矩估计的用于随机目标函数的一阶梯度优化算法。</p><p>The hyper-parameters have intuitive interpretations and typically require little tuning.</p><p>超参数具有直观的解释，通常需要很少的调整。</p><p>Some connections to related algorithms, on which Adam was inspired, are discussed.</p><p>讨论了一些对Adam启发的相关算法的联系</p><p>We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework.</p><p>我们还分析了算法的理论收敛性，并提供了与在线凸优化框架下已知的最好的结果相当的收敛率的后悔界。</p><p>Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods.</p><p>实证结果表明，Adam在实践中效果很好，并且可以与其他随机优化方法进行比较。</p><p>Because the available data typically only covers a small manifold of the possible space of inputs, a principal challenge is to be able to construct algorithms that can reason about uncertainty and out-of-distribution values, since a naive optimizer can easily exploit an estimated model to return adversarial inputs.</p><p>由于可用数据通常仅覆盖输入空间的一小部分，因此主要的挑战是能够构造出一个算法可以对不确定性和分布以外的数据进行推理，因为本地的优化器可以轻松利用估计的模型返回对抗性输入。</p><p>We propose to tackle this problem by leveraging the normalized maximum-likelihood (NML) estimator, which provides a principled approach to handling uncertainty and out-of-distribution inputs.</p><p>我们提出通过利用归一化的最大似然（ML）估计来解决此问题，该估计提供了一种处理不确定性和分布失调输入的原则方法。</p><p>We demonstrate that our method can effectively optimize high-dimensional design problems in a variety of disciplines such as chemistry, biology, and materials engineering.</p><p>我们证明了我们的方法可以有效地优化化学，生物学和材料工程等众多学科中的高维设计问题。</p><p>The analysis of the learned algorithm behavior shows resemblance to recently proposed RL algorithms that address overestimation in value-based methods.</p><p>对学习到的算法行为的分析表明，它与最近提出的RL算法相似，后者解决了基于值的方法中的高估问题。</p><h2 id="introduction">Introduction</h2><p>Stochastic gradient-based optimization is of core practical importance in many fields of science and engineering</p><p>基于随机梯度的优化在科学和工程学的许多领域中具有核心的实践重要性</p><p>Many problems in these fields can be cast as the optimization of some scalar parameterized objective function requiring maximization or minimization with respect to its parameters.</p><p>这些领域中的许多问题都可以归结为某些标量参数化目标函数的优化，要求对其参数进行最大化或最小化。</p><p>If the function is differentiable w.r.t. its parameters, gradient descent is a relatively efficient optimization method, since the computation of first-order partial derivatives w.r.t. all the parameters is of the same computational complexity as just evaluating the function.</p><p>如果函数是可微的 由于其一阶偏导数w.r.t的计算，梯度下降是一种相对有效的优化方法。 所有参数的计算复杂度与评估函数相同。</p><p>The focus of this paper is on the optimization of stochastic objectives with high-dimensional parameters spaces.</p><p>本文的重点是优化具有高维参数空间的随机目标。</p><p>Some of Adam’s advantages are that the magnitudes of parameter updates are invariant to rescaling of the gradient, its stepsizes are approximately bounded by the stepsize hyperparameter, it does not require a stationary objective, it works with sparse gradients, and it naturally performs aform of step size annealing.</p><p>Adam的一些优点是参数更新的大小对于梯度的重新缩放是不变的，其步长大约由步长超参数界定，它不需要固定的目标函数，它适用于稀疏梯度，并且自然地执行阶跃形式 尺寸退火。</p><p>Many real-world optimization problems involve function evaluations that are the result of expensive or time-consuming process.</p><p>许多实际的优化问题都涉及功能评估，这是昂贵或耗时的过程的结果。</p><p>Rather than settling for a slow and expensive optimization process through repeated function evaluations, one may instead adopt a data-driven approach, where a large dataset of previously collected input-output pairs is given in lieu of running expensive function queries.</p><p>与其通过重复的函数评估来解决缓慢而昂贵的优化过程，不如采用一种数据驱动的方法，其中使用大量先前收集的输入输出对数据集代替运行昂贵的函数查询。</p><p>A straightforward method to solving offline MBO problems would be to estimate a proxy of the ground truth function f^θ using supervised learning, and to optimize the input x with respect to this proxy.</p><p>解决离线MBO问题的一种直接方法是使用监督学习估计真实函数的替代函数，并且针对该替代函数优化输入x。</p><p>The main contribution of this work is to develop an offline MBO algorithm that utilizes a novel approximation to the NML distribution to obtain an uncertainty-aware forward model for optimization, which we call NEMO (Normalized maximum likelihood Estimation for Model-based Optimization).</p><p>这项工作的主要贡献是开发一种离线MBO算法，该算法利用一个新颖的近似算法来近似NML分布，来获得不确定性感知的正向模型以进行优化，我们将其称为NEMO（基于模型的优化的归一化最大似然估计）。</p><p>Designing new deep reinforcement learning algorithms that can efficiently solve across a wide variety of problems generally requires a tremendous amount of manual effort.</p><p>设计能够有效解决各种问题的新的深度强化学习算法通常需要大量的人工工作。</p><p>Learning to design reinforcement learning algorithms or even small sub-components of algorithms would help ease this burden and could result in better algorithms than researchers could design manually.</p><p>学习设计强化学习算法甚至算法的较小子组件将有助于减轻这种负担，并且可能会产生比研究人员可以手动设计的更好的算法。</p><p>While learning from scratch is generally less biased, encoding existing human knowledge into the learning process can speed up the optimization and also make the learned algorithm more interpretable.</p><p>虽然从头开始学习通常没有什么偏见，但是将现有的人类知识编码到学习过程中可以加快优化速度，并使学习的算法更具可解释性。</p><p>We learn two new RL algorithms which outperform existing algorithms in both sample efficiency and final performance on the training and test environments.</p><p>我们学习了两种新的RL算法，它们在训练和测试环境中的采样效率和最终性能均优于现有算法。</p><p>The contribution of this paper is a method for searching over the space of RL algorithms, which we instantiate by developing a formal language that describes a broad class of value-based model-free reinforcement learning methods.</p><p>本文的贡献是一种用于搜索RL算法空间的方法，我们通过开发一种形式语言来实例化该方法，该语言描述了一大类基于值的无模型强化学习方法。</p><h2 id="related-work">Related work</h2><p>However, all of the aforementioned methods focus on the active or online setting, whereas in this work, we are concerned with the offline setting where additional function evaluations are not available.</p><p>但是，所有上述方法都集中在在线环境中，然而在这项工作中，我们关注的是离线环境，在该设置下无法进行其他功能评估。</p><p>Bibas et al. (2019) apply this framework for prediction using deep neural networks, but require an expensive fine tuning process for every input.</p><p>Bibas等将这种框架应用于使用深度神经网络的预测，但需要为每个输入进行昂贵的微调过程。</p><p>The goal of our work is to provide a scalable and tractable method to approximate the CNML distribution, and we apply this framework to offline optimization problems.</p><p>我们工作的目标是提供一种可扩展且易于处理的方法来近似CNML分布，并将此框架应用于离线优化问题。</p><p>The estimation of distribution algorithm (Bengoetxea et al., 2001) alternates between searching in the input space and model space using a maximum likelihood objective.</p><p>分布算法的估计（Bengoetxea等，2001）使用最大似然目标在输入空间和模型空间中进行搜索之间交替。</p><p>One is in contextual bandits under the batch learning from bandit feedback setting, where learning is often done on logged experience (Swaminathan &amp; Joachims, 2015; Joachims et al., 2018), or offline reinforcement learning (Levine et al., 2020), where model-based methods construct estimates of the MDP parameters.</p><p>需要修改：一种是在从匪徒反馈设置中进行批处理学习的情境匪徒中，学习通常是基于记录的经验（Swaminathan＆Joachims，2015； Joachims等，2018）或离线强化学习（Levine等，2020）， 其中基于模型的方法构造了MDP参数的估计值。</p><h2 id="method">Method</h2><p>This can be understood as establishing a trust region around the current parameter value, beyond which the current gradient estimate does not provide sufficient information.</p><p>这可以理解为在当前参数值周围建立信任区域，超过该范围当前梯度估计将无法提供足够的信息。</p><p>For many machine learning models, for instance, we often know in advance that good optima are with high probability within some set region in parameter space</p><p>例如，对于许多机器学习模型，我们通常会事先知道，在参数空间的某些设置区域内，良好的最优概率很高</p><p>This is a desirable property, since a smaller SNR means that there is greater uncertainty about whether the direction of mb t corresponds to the direction of the true gradient.</p><p>这是一个理想的特性，因为SNR越小意味着mb t的方向是否对应于真实梯度的方向的不确定性就越大。</p><p>Let g be the gradient of the stochastic objective f, and we wish to estimate its second raw moment (uncentered variance) using an exponential moving average of the squared gradient, with decay rate β2. Let g1, ..., gT be the gradients at subsequent timesteps, each a draw from an underlying gradient distribution gt ∼ p(gt).</p><p>令g为随机目标f的梯度，我们希望使用平方梯度的指数移动平均值（衰减率为β2）来估计其第二原始矩（无中心方差）。 令g1，...，gT为后续时间步长的梯度，每个梯度都是从基础梯度分布gt〜p（gt）中得出的。</p><p>We wish to know how E[vt], the expected value of the exponential moving average at timestep t, relates to the true second moment E[gt2], so we can correct for the discrepancy between the two.</p><p>我们希望知道E [vt]，即时间步长t处的指数移动平均值的期望值与真实的第二矩E [gt2]之间的关系，因此我们可以校正两者之间的差异。</p><p>Since the nature of the sequence is unknown in advance, we evaluate our algorithm using the regret, that is the sum of all the previous difference between the online prediction ft(θt) and the best fixed point parameter ft(θ∗) from a feasible set X for all the previous steps.</p><p>由于序列的性质事先未知，因此我们遗憾地评估了我们的算法，即在线预测ft（θt）和最佳定点参数ft（θ∗）之间所有先前差值的总和。 为前面的所有步骤设置X。</p><p>However, in offline MBO, the algorithm is not allowed to query the true function f(yjx), and must find the best possible point x∗ using only the guidance of a fixed dataset D = fx1:N ; y1:Ng.</p><p>但是，在离线MBO中，该算法不允许查询真实函数f，并且必须仅在固定数据集D的指导下找到最佳可能点x。</p><p>While adversarial ground truth functions can easily be constructed where this is the best one can do (e.g., if f(x) = −1 on any x = 2 D), in many reasonable domains it should be possible to perform better than the best point in the dataset.</p><p>需要修改：尽管可以轻松地构造出最佳的对抗性地面真理函数（例如，如果在任意x = 2 D上f（x）= -1），但在许多合理的域中，应该有可能比最佳的表现更好点在数据集中。</p><p>One of the primary contributions of this paper is to discuss how to approximate this intractable computation with a tractable one that is sufficient for optimization on challenging problems, which we discuss in Section 4.</p><p>需要修改：本文的主要贡献之一是讨论如何用一种足以解决难题的优化方法的易处理性来逼近这一难处理的计算，我们将在第4节中进行讨论。</p><p>To remedy this problem, we propose to amortize the learning process by incrementally learning the NML distribution while optimizing the iterate xt.</p><p>需要修改：为了解决这个问题，我们建议在优化迭代xt的同时通过逐步学习NML分布来摊销学习过程。</p><p>While quantization has potential to induce additional rounding errors to the optimization process, we find in our experiments in Section 5 that using moderate value such as K = 20 or K = 40 provides both a reasonably accurate solution while not being excessively demanding on computation.</p><p>尽管量化有可能在优化过程中引起额外的舍入误差，但我们在第5节的实验中发现，使用中等值（例如K = 20或K = 40）既可以提供合理的精度，又不会对计算产生过多的要求。</p><p>We now highlight some theoretical motivation for using CNML in the MBO setting, and show that estimating the true function with the CNML distribution is close to an expert even if the test label is chosen adversarially, which makes it difficult for an optimizer to exploit the model.</p><p>需要修改：现在，我们重点介绍了在MBO设置中使用CNML的一些理论动机，并表明，即使测试标签是经过逆向选择的，使用CNML分布来估计真实函数也很接近专家，这使得优化器难以利用模型 。</p><h2 id="simulation">Simulation</h2><p>To empirically evaluate the proposed method, we investigated different popular machine learning models, including logistic regression, multilayer fully connected neural networks and deep convolutional neural networks.</p><p>为了从经验上评估所提出的方法，我们研究了各种流行的机器学习模型，包括逻辑回归，多层完全连接神经网络和深度卷积神经网络。</p><p>Logistic regression has a well-studied convex objective, making it suitable for comparison of different optimizers without worrying about local minimum issues.</p><p>Logistic回归具有经过充分研究的凸目标，使其适合比较不同的优化器，而不必担心局部最小问题。</p><p>In our experiments, we made model choices that are consistent with previous publications in the area; a neural network model with two fully connected hidden layers with 1000 hidden units each and ReLU activation are used for this experiment with minibatch size of 128.</p><p>在我们的实验中，我们做出了与该领域以前的出版物一致的模型选择。 该神经网络模型具有两个完全连接的隐藏层，每个隐藏层各具有1000个隐藏单元，并且ReLU激活用于最小批量为128的实验。</p><p>Due to the cost of updating curvature information, SFO is 5-10x slower per iteration compared to Adam, and has a memory requirement that is linear in the number minibatches.</p><p>由于更新曲率信息的成本，SFO与Adam相比，每次迭代的速度慢5-10倍，并且内存需求在微型批处理中是线性的。</p><p>Whereas, reducing the minibatch variance through the first moment is more important in CNNs and contributes to the speed-up.</p><p>然而，在CNN中降低第一时刻的最小批量差异更为重要，并有助于提高速度。</p><p>Though Adam shows marginal improvement over SGD with momentum, it adapts learning rate scale for different layers instead of hand picking manually as in SGD.</p><p>尽管Adam在动量方面比SGD略有改善，但它会针对不同层次调整学习率范围，而不是像SGD中那样手动进行选择。</p><p>The details for the tasks, baselines, and experimental setup are as follows, and hyperparameter choices with additional implementation details can be found in Appendix A.2</p><p>任务，基准和实验设置的详细信息如下，附录A.2中提供了带有其他实现详细信息的超参数选择。</p><p>Because we do not have access to a real physical process for evaluating the material and molecule design tasks, Design-bench follows experimental protocol used in prior work (Brookes et al., 2019; Fannjiang &amp; Listgarten, 2020) which obtains a ground truth evaluation function by training a separate regressor model to evaluate the performance of designs.</p><p>由于我们无法使用真实的物理过程来评估材料和分子设计任务，因此设计台遵循先前工作中使用的实验方案（Brookes等人，2019年; Fannjiang＆Listgarten，2020年），该方法可获取地面真实性评估 通过训练一个单独的回归模型来评估设计性能来发挥作用。</p><p>CbAS uses a generative model of p(x) as a trust region to prevent model exploitation, and autofocused oracles expands upon CbAS by iteratively updating the learned proxy function and iterates within a minimax game based on a quantity known as the oracle gap.</p><p>CbAS使用p（x）的生成模型作为信任区域来防止模型被利用，并且自动聚焦的Oracle通过迭代更新所学习的代理函数来扩展CbAS，并基于称为Oracle缺口的数量在minimax游戏中进行迭代。</p><p>NEMO outperforms all methods on the Superconductor task by a very large margin, under both the 100th and 50th percentile metrics, and in the HopperController task under the 100th percentile metric.</p><p>在第100和第50个百分位数指标下，NEMO在超导体任务上的所有方法的性能都非常好，在第100个百分位指标下，其性能在HopperController任务中均胜过所有方法。</p><p>These results are promising in that NEMO performs consistently well across all 6 domains evaluated, and indicates a significant number of designs found in the GFP and Superconductor task were better than the best performing design in the dataset.</p><p>这些结果令人鼓舞，因为NEMO在所有评估的6个域中始终表现良好，并且表明在GFP和超导体任务中发现的大量设计都比数据集中表现最佳的设计要好。</p><h2 id="conclusion">Conclusion</h2><p>Our method is aimed towards machine learning problems with large datasets and/or high-dimensional parameter spaces.</p><p>我们的方法旨在解决大型数据集和/或高维参数空间的机器学习问题。</p><p>Overall, we found Adam to be robust and well-suited to a wide range of non-convex optimization problems in the field machine learning.</p><p>总体而言，我们发现Adam非常强大，非常适合于现场机器学习中的各种非凸优化问题。</p><p>We have presented NEMO (Normalized Maximum Likelihood Estimation for Model-Based Optimization), an algorithm that mitigates model exploitation on MBO problems by constructing a conservative model of the true function.</p><p>我们介绍了NEMO（基于模型的优化的归一化最大似然估计），该算法通过构造真实函数的保守模型来减轻MBO问题上的模型开发。</p><p>We evaluated NEMO on a number of design problems in materials science, robotics, biology, and chemistry, where we show that it attains very large improvements on two tasks, while performing competitively with respect to prior methods on the other four.</p><p>我们在材料科学，机器人技术，生物学和化学领域的许多设计问题上对NEMO进行了评估，结果表明NEMO在两项任务上均取得了很大的改进，而在其他四项任务上却比以前的方法更具竞争力。</p><p>We design a general language for representing algorithms which compute the loss function for value-based model-free RL agents to optimize.</p><p>我们设计了一种通用语言来表示算法，该算法可为基于价值的无模型RL代理计算损失函数以进行优化。</p><p>We highlight two learned algorithms which although relatively simple, can obtain good generalization performance over a wide range of environments.</p><p>我们重点介绍了两种学习算法，这些算法虽然相对简单，但可以在广泛的环境中获得良好的泛化性能。</p><p>Our analysis of the learned algorithms sheds insight on their benefit as regularization terms which are similar to recently proposed algorithms.</p><p>我们对所学算法的分析揭示了它们作为正则化术语的好处，与最近提出的算法相似。</p></div><div class="post-copyright-info w-full my-8 px-2 sm:px-6 md:px-8"><div class="article-copyright-info-container"><ul><li><strong>标题:</strong> 科研论文常用句式语法汇总整理</li><li><strong>作者:</strong> Oliver xu</li><li><strong>创建于 :</strong> 2021-01-31 19:09:00</li><li><strong>更新于 :</strong> 2026-02-28 21:09:01</li><li><strong>链接:</strong> https://blog.oliverxu.cn/2021/01/31/科研论文常用句式语法汇总整理/</li><li><strong>版权声明: </strong>本文章采用 <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0">CC BY-NC-SA 4.0</a> 进行许可。</li></ul></div></div><ul class="post-tags-box text-lg mt-1.5 flex-wrap justify-center flex md:hidden"><li class="tag-item mx-0.5"><a href="/tags/Paper/">#Paper</a>&nbsp;</li></ul><div class="article-nav my-8 flex justify-between items-center px-2 sm:px-6 md:px-8"><div class="article-prev border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2"><a class="prev" rel="prev" href="/2021/02/28/%E7%A7%91%E7%A0%94%E8%AE%BA%E6%96%87%E5%90%84%E6%AE%B5%E8%90%BD%E8%A1%A8%E8%BE%BE%E6%95%B4%E7%90%86%E8%83%8C%E8%AF%B5/"><span class="left arrow-icon flex justify-center items-center"><i class="fa-solid fa-chevron-left"></i> </span><span class="title flex justify-center items-center"><span class="post-nav-title-item">科研论文各段落表达整理背诵</span> <span class="post-nav-item">上一篇</span></span></a></div><div class="article-next border-border-color shadow-redefine-flat shadow-shadow-color-2 rounded-medium px-4 py-2 hover:shadow-redefine-flat-hover hover:shadow-shadow-color-2"><a class="next" rel="next" href="/2021/01/09/Tensorboard%E4%B8%AD%E7%9A%84%E5%9B%BE%E6%94%BE%E5%88%B0%E8%AE%BA%E6%96%87%E4%B8%AD/"><span class="title flex justify-center items-center"><span class="post-nav-title-item">Tensorboard中的图放到论文中</span> <span class="post-nav-item">下一篇</span> </span><span class="right arrow-icon flex justify-center items-center"><i class="fa-solid fa-chevron-right"></i></span></a></div></div><div class="comment-container px-2 sm:px-6 md:px-8 pb-8"><div class="comments-container mt-10 w-full"><div id="comment-anchor" class="w-full h-2.5"></div><div class="comment-area-title w-full my-1.5 md:my-2.5 text-xl md:text-3xl font-bold">评论</div><div id="gitalk-container"></div><script data-swup-reload-script src="https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.min.js"></script><script data-swup-reload-script>function loadGitalk(){let e=decodeURI(location.pathname);e.length>50&&(e=e.substring(0,47)+"...");try{Gitalk&&new Gitalk({clientID:"e11777414ce827fd8ec2",clientSecret:"c572c4ca1c0dfdfaf2b4f2195aa903185e2dfeea",repo:"blog-comment",owner:"olixu",admin:["olixu"],id:e,language:"zh-CN",proxy:"https://strong-caramel-969805.netlify.app/github_access_token"}).render("gitalk-container")}catch(e){window.Gitalk=null}}{const e=setTimeout(()=>{loadGitalk(),clearTimeout(e)},1e3)}</script></div></div></div><div class="toc-content-container"><div class="post-toc-wrap"><div class="post-toc"><div class="toc-title">目录</div><div class="page-title">科研论文常用句式语法汇总整理</div><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#abstract"><span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#introduction"><span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#related-work"><span class="nav-text">Related work</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#method"><span class="nav-text">Method</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#simulation"><span class="nav-text">Simulation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#conclusion"><span class="nav-text">Conclusion</span></a></li></ol></div></div></div></div></div></div><div class="main-content-footer"><footer class="footer mt-5 py-5 h-auto text-base text-third-text-color relative border-t-2 border-t-border-color"><div class="info-container py-3 text-center"><div class="text-center">&copy; <span>2019</span> - 2026&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration:0.5s;color:#f54545"></i>&nbsp;&nbsp;<a href="/">Oliver xu</a><p class="post-count space-x-0.5"><span>共撰写了 94 篇文章 </span><span>共 123k 字</span></p></div><script data-swup-reload-script src="https://cn.vercount.one/js"></script><div class="relative text-center lg:absolute lg:right-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-right"><span id="busuanzi_container_site_uv" class="lg:!block"><span class="text-sm">访问人数</span> <span id="busuanzi_value_site_uv"></span> </span><span id="busuanzi_container_site_pv" class="lg:!block"><span class="text-sm">总访问量</span> <span id="busuanzi_value_site_pv"></span></span></div><div class="relative text-center lg:absolute lg:left-[20px] lg:top-1/2 lg:-translate-y-1/2 lg:text-left"><span class="lg:block text-sm">由 <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg class="relative top-[2px] inline-block align-baseline" version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" class="text-base" href="https://hexo.io">Hexo</a> 驱动</span> <span class="text-sm lg:block">主题&nbsp;<a class="text-base" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.7.3</a></span></div><div class="icp-info my-1"><a target="_blank" rel="nofollow" href="https://beian.miit.gov.cn">苏ICP备17055396号</a></div><div>博客已运行 <span class="odometer" id="runtime_days"></span> 天 <span class="odometer" id="runtime_hours"></span> 小时 <span class="odometer" id="runtime_minutes"></span> 分钟 <span class="odometer" id="runtime_seconds"></span> 秒</div><script data-swup-reload-script>try{function odometer_init(){document.querySelectorAll(".odometer").forEach(e=>{new Odometer({el:e,format:"( ddd).dd",duration:200})})}odometer_init()}catch(e){}</script></div></footer></div></div><div class="post-tools"><div class="post-tools-container"><ul class="article-tools-list"><li class="right-bottom-tools page-aside-toggle"><i class="fa-regular fa-outdent"></i></li><li class="go-comment"><i class="fa-regular fa-comments"></i></li></ul></div></div><div class="right-side-tools-container"><div class="side-tools-container"><ul class="hidden-tools-list"><li class="right-bottom-tools tool-font-adjust-plus flex justify-center items-center"><i class="fa-regular fa-magnifying-glass-plus"></i></li><li class="right-bottom-tools tool-font-adjust-minus flex justify-center items-center"><i class="fa-regular fa-magnifying-glass-minus"></i></li><li class="right-bottom-tools tool-dark-light-toggle flex justify-center items-center"><i class="fa-regular fa-moon"></i></li><li class="right-bottom-tools tool-scroll-to-bottom flex justify-center items-center"><i class="fa-regular fa-arrow-down"></i></li></ul><ul class="visible-tools-list"><li class="right-bottom-tools toggle-tools-list flex justify-center items-center"><i class="fa-regular fa-cog fa-spin"></i></li><li class="right-bottom-tools tool-scroll-to-top flex justify-center items-center"><i class="arrow-up fas fa-arrow-up"></i> <span class="percent"></span></li></ul></div></div><div class="image-viewer-container"><img src=""></div><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-input-field-pre"><i class="fa-solid fa-keyboard"></i></span><div class="search-input-container"><input autocomplete="off" autocorrect="off" autocapitalize="off" placeholder="站内搜索您需要的内容..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa-solid fa-times"></i></span></div><div id="search-result"><div id="no-result"><i class="fa-solid fa-spinner fa-spin-pulse fa-5x fa-fw"></i></div></div></div></div></main><script src="/js/libs/Swup.min.js"></script><script src="/js/libs/SwupSlideTheme.min.js"></script><script src="/js/libs/SwupScriptsPlugin.min.js"></script><script src="/js/libs/SwupProgressPlugin.min.js"></script><script src="/js/libs/SwupScrollPlugin.min.js"></script><script src="/js/libs/SwupPreloadPlugin.min.js"></script><script>const swup=new Swup({plugins:[new SwupScriptsPlugin({optin:!0}),new SwupProgressPlugin,new SwupScrollPlugin({offset:80}),new SwupSlideTheme({mainElement:".main-content-body"}),new SwupPreloadPlugin],containers:["#swup"]})</script><script src="/js/tools/imageViewer.js" type="module"></script><script src="/js/utils.js" type="module"></script><script src="/js/main.js" type="module"></script><script src="/js/layouts/navbarShrink.js" type="module"></script><script src="/js/tools/scrollTopBottom.js" type="module"></script><script src="/js/tools/lightDarkSwitch.js" type="module"></script><script src="/js/layouts/categoryList.js" type="module"></script><script src="/js/tools/localSearch.js" type="module"></script><script src="/js/tools/codeBlock.js" type="module"></script><script src="/js/layouts/lazyload.js" type="module"></script><script src="/js/tools/runtime.js"></script><script src="/js/libs/odometer.min.js"></script><link rel="stylesheet" href="/assets/odometer-theme-minimal.css"><script src="/js/libs/Typed.min.js"></script><script src="/js/plugins/typed.js" type="module"></script><script src="/js/libs/anime.min.js"></script><script src="/js/tools/tocToggle.js" type="module" data-swup-reload-script=""></script><script src="/js/layouts/toc.js" type="module" data-swup-reload-script=""></script><script src="/js/plugins/tabs.js" type="module" data-swup-reload-script=""></script><script src="/js/libs/moment-with-locales.min.js" data-swup-reload-script=""></script><script src="/js/layouts/essays.js" type="module" data-swup-reload-script=""></script></body></html>